<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-09-29T17:28:18+10:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">TWâ€™s Home</title><subtitle>Hi! Welcome to my website. I am hoping to post content related to mathematics and statistics here during my studies and beyond.  Hosted on Github Pages using Jekyll. Mathematical equations are displayed with MathJax.</subtitle><entry><title type="html">Introduction</title><link href="http://localhost:4000/introductions/2021/09/29/Ideas_to_write_about.html" rel="alternate" type="text/html" title="Introduction" /><published>2021-09-29T16:28:00+10:00</published><updated>2021-09-29T16:28:00+10:00</updated><id>http://localhost:4000/introductions/2021/09/29/Ideas_to_write_about</id><content type="html" xml:base="http://localhost:4000/introductions/2021/09/29/Ideas_to_write_about.html">&lt;p&gt;Of course, one must have some ideas on what to write on before beginning to write! I am thinking of the following:
Basic distributions/statistics summary
Bayesian inference introduction
Basic machine learning algorithms&lt;/p&gt;

&lt;p&gt;To be honest, I still have a lot to learn before I can confidently write on these topics.&lt;/p&gt;

&lt;p&gt;The Bayesian Framework:&lt;/p&gt;

\[\pi(\theta \mid x) = \frac{\pi(x \mid \theta)\pi(\theta)}{m(x)}\]

&lt;p&gt;where \(m(x)\) represents the marginal distribution of \(x\), \(\pi(\theta)\) is the prior distribution of the parameters \(\theta\) and \(\pi(x\mid \theta)\) is the likelihood function. Beware, however, that we are viewing \(\pi(x\mid \theta)\) as a function of the parameters \(\theta\) and the data \(x\) is fixed; often, this dependence is made explicit by writing 
\(\pi(x\mid \theta) = L(\theta; x).\)&lt;/p&gt;</content><author><name>Tony Wang</name></author><category term="Introductions" /><summary type="html">Of course, one must have some ideas on what to write on before beginning to write! I am thinking of the following: Basic distributions/statistics summary Bayesian inference introduction Basic machine learning algorithms</summary></entry><entry><title type="html">Introduction</title><link href="http://localhost:4000/introductions/2021/09/16/First.html" rel="alternate" type="text/html" title="Introduction" /><published>2021-09-16T23:34:48+10:00</published><updated>2021-09-16T23:34:48+10:00</updated><id>http://localhost:4000/introductions/2021/09/16/First</id><content type="html" xml:base="http://localhost:4000/introductions/2021/09/16/First.html">&lt;p&gt;My first post.&lt;/p&gt;

&lt;p&gt;Do equations work? 
\(x + y = 1 \quad \int_\Omega A(x,u,\nabla u) : dx = f\)&lt;/p&gt;</content><author><name>Tony Wang</name></author><category term="Introductions" /><summary type="html">My first post.</summary></entry></feed>